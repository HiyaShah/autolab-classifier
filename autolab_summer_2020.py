# -*- coding: utf-8 -*-
"""Final AI4ALL AUTOLab Summer 2020 Project GROUP 1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1jgitjvxMLuPZRXhotLRNTVGMYGbaw9c3

LINK TO DATA: https://drive.google.com/drive/folders/1yBWKw7y2m65y4qVamve2Ro6MBPsuIOUj?usp=sharing

In this notebook, you will go through the process of taking a pre-existing neural network, "fine tuning" it on new data, and then evaluating the resulting network model on a dataset of your choice.

First, we will import some libraries that will be useful for constructing and evaluating our network. Notably, we will use the Keras package: Keras is an open-source neural-network library that can run on top of the machine learning framework TensorFlow. Keras is user-friendly and is great for fast experimentation with deep neural networks.
"""

# Importing Python Libraries
from keras.applications.resnet50 import ResNet50
from keras.applications.xception import Xception

from keras.layers import Input
from keras.layers import Dense, Dropout, Flatten
from tensorflow.keras import Sequential, optimizers
from keras.preprocessing import image
from keras.applications.resnet50 import preprocess_input, decode_predictions
from google.colab import files
from matplotlib.pyplot import imshow
import matplotlib.pyplot as plt
import numpy as np
import keras
import os
from keras.preprocessing.image import ImageDataGenerator

"""Now, we will mount your Google Drive to the Colab notebook. Replace the string assigned to drive_path with the path to the directory you want to share with the notebook."""

# Mounting Google Drive

drive_path = '/content/drive' # REPLACE WITH YOUR PATH HERE

from google.colab import drive
drive.mount(drive_path)

"""Below is an illustration of the fine-tuning process we will be using in this notebook. First, observe the architecture of the "source task" neural network in the top row. Neural networks are comprised of a composition of functions called layers. Input images are passed into a series of "convolutional layers", followed by a series of "fully-connected layers". The convolutional layers typically identify distinguishing features of images (the features they identify depends on the data passed in during training!) and the fully connected layers take the features from the convolutional layers and use them to classify the image.

In fine-tuning, we take the first n trained layers and "freeze" their parameters, meaning that if we train the network these layers will not be modified. We then add a small number of layers at the very end of the network and do *not* freeze them. Then, when we train the network on a new set of images and classes, the layers that learned to identify features in images will still produce the same features, but the final layers that take those features and classify the images will learn to make new classifications based on the training data.

**Fine Tuning from ImageNet to Tumor Classification**

![alt text](https://www.researchgate.net/publication/328680040/figure/fig1/AS:688421848752129@1541143967564/Schematic-representation-of-convolutional-neural-network-CNN-architecture-and-the.png)

Now we will import our base model. Over the years, researchers have developed a variety of high-performing neural networks that are excellent at identifying distinguishing features in images. Many of these networks are built into the Keras library and can be imported with the line `from keras.applications.resnet50 import ResNet50` (see the first cell of the notebook). Networks need to be "trained" on data before they can be useful, but these built-in models are imported pre-trained based on the weights provided as a parameter. Check out this page (https://keras.io/api/applications/) for a list of easily importable models. Once you finish going through the notebook, come back to this cell and see how other models compare to the ResNet50 provided below.
"""

# https://keras.io/guides/transfer_learning/

# Image Settings
image_height = 224
image_width = 224

# Define the input placeholder of the neural network. This is what we will be passing our images into
input_tensor = Input(shape=(image_height, image_width, 3))

# Add the base neural network that we will be fine-tuning.
    # input_tensor: This is the input placeholder that we defined above
    # weights: These are the parameters that tell our model how to behave.
    # include_top: This determines whether or not we want the last layers of the network that actually do the classifying.
    #              We do not want to include these layers in our model, because we will be introducing our own layers that will classify based on our training.
base_model = Xception(input_tensor=input_tensor, weights='imagenet', include_top=False)

# Freeze all the layers
base_model.trainable = False

"""Now, we will add our fine-tuning layers to place at the end of the network. We start you off with a fairly standard series of final layers, but there are a vast number of architectures that can be used. Once you run through the notebook the first time, try out different architectures for the end of the network using the layers listed at this link: https://keras.io/api/layers/. Feel free to try out different numbers of layers, different types of layers, and different orderings.

Here are some of the layers you might use:


*   Dense: A standard fully-connected layer.
*   Dropout: Randomly sets a group of input units to zero. Can improve classification accuracy.
*   Flatten: "Flattens" a multi-dimensional input (aka an output from a convolutional layer) so it works well with later layers
"""

# https://www.learnopencv.com/keras-tutorial-fine-tuning-using-pre-trained-models/
hidden_layer_size = 1024
dropout_param = 0.5
num_categories = 2
inputs = keras.Input(shape=(224, 224, 3))

#Try playing around with different activation functions and layers: https://keras.io/api/layers/
#model.add(Dense(hidden_layer_size, activation='relu'))
#model.add(Dropout(dropout_param))
#model.add(Dense(num_categories, activation='softmax'))

x = base_model(inputs)
x = Flatten()(x)
x = Dense(hidden_layer_size, activation='relu')(x)
x = Dropout(dropout_param)(x)
outputs = Dense(num_categories, activation='softmax')(x)
model = keras.Model(inputs, outputs)
for layer in model.layers:
    print(layer, layer.trainable)

"""Now we are almost ready to fine-tune our network. There's just one problem: We need data to train it on. Luckily, since we're just fine tuning our model we don't need a massive amount of images. Go onto Google and collect a set of images for each category you would like to classify and put them into folders organized by class. Give each folder the name of the category it has images of. The more images, the better your network will be, but data collection can take a long time. Start out with ~20 images per class, and if your model isn't as robust as you'd like it to be, collect some more and try again.

Once you've collected your training data, we can create our training and validation datasets. In machine learning, we divide data into three groups: Training, validation, and test. Training data is used to teach the network to classify things correctly. Validation data is then used to assess the performance of the network on new, unseen data. Test data is special: It is only used once at the end of the model development process to assess the final performance of the network. We only want to use our test data once, because if we then attempt to modify the network based on the results produced by the test data, the test set is no longer an unbiased estimate of the network's effectiveness.
"""

# replace these strings with paths to a training folder and a validation folder.
# We recommend putting about 75% of your data in the training folder, and the rest
# in the validation folder. We will provide you with test data at the end of
# the notebook. Within your training and validation folders, put one folder for
# each class and set the folder name to the name of the class.

train_dir = 'drive/My Drive/DATA/training'
validation_dir = 'drive/My Drive/DATA/validation'
labelsT = os.listdir(train_dir)
labelsV = os.listdir(validation_dir)
print(labelsT, labelsV)

# Load the normalized images
train_datagen = ImageDataGenerator(rescale=1./255)
validation_datagen = ImageDataGenerator(rescale=1./255)
 
# Try changing the batchsize! This is the number of images that will be passed
# into the network at a time, and will affect how the network learns.
train_batchsize = 50
val_batchsize = 50
 
# Data generator for training data
train_generator = train_datagen.flow_from_directory(
        train_dir,
        target_size=(image_height, image_width),
        batch_size=train_batchsize,
        class_mode='categorical')
 
# Data generator for validation data
validation_generator = validation_datagen.flow_from_directory(
        validation_dir,
        target_size=(image_height, image_width),
        batch_size=val_batchsize,
        class_mode='categorical',
        shuffle=False)

"""Now we will fine-tune the model by training the final layers of the network that we added. The compile function takes in a few parameters that will determine how the model learns. Feel free to modify the optimizer parameter. For loss, you will probably want to use a categorical loss function for optimal performance---some loss functions are designed for predicting among multiple classes, but others work best for networks that predict between binary classes or actual values as opposed to classes. However, we have more leeway with the optimizer. Check out possibilities here: https://keras.io/api/optimizers/

Most of the parameters passed into model.fit will need to stay the same as we are just passing in the data, but feel free to modify the epochs parameter. This determines how long we train the model for.
"""

# Configure the model for training
model.compile(loss='categorical_crossentropy',
              optimizer=optimizers.Adam(learning_rate=1e-4),
              metrics=['acc'])

# Train the model
history = model.fit(train_generator, steps_per_epoch=train_generator.samples/train_generator.batch_size, 
                    epochs=20, validation_data=validation_generator, 
                    validation_steps=validation_generator.samples/validation_generator.batch_size, verbose=1)

"""Run the following code to visualize the training and validation accuracy below. The training accuracy denotes the effectiveness of the model on the training data, and the validation accuracy shows the effectiveness of the model on new, unseen data. Do you notice any trends? Is the training or validation accuracy higher? Why do you think that is?"""

def visualize_results(history):
  # Plot the accuracy and loss curves
  acc = history.history['acc']
  val_acc = history.history['val_acc']
  loss = history.history['loss']
  val_loss = history.history['val_loss']
  epochs = range(len(acc))
  
  plt.plot(epochs, acc, 'b', label='Training acc')
  plt.plot(epochs, val_acc, 'r', label='Validation acc')
  plt.title('Training and validation accuracy')
  plt.legend()
  plt.figure()
  
  plt.plot(epochs, loss, 'b', label='Training loss')
  plt.plot(epochs, val_loss, 'r', label='Validation loss')
  plt.title('Training and validation loss')
  plt.legend()
  plt.show()

# Run the function to illustrate accuracy and loss
visualize_results(history)

"""Now that we have trained our model, we can visualize its performance on individual images. Try passing in an image and see what the network outputs."""

# Select Desired Photo
images = files.upload()

i = 0
for file in images:
  filename = list(images)[i]
  
  # Load Image
  img = image.load_img(filename, target_size=(image_height, image_width))
    
  # Display the image
  plt.figure()
  imshow(np.asarray(img))
  
  # Preprocessing Steps
  x = image.img_to_array(img)
  x = np.expand_dims(x, axis=0)
  x = preprocess_input(x)
  
  # Neural Network Predictions of Selected Image
  predictions = model.predict(x)
  print(list(zip(predictions[0], labels)))
  print()

"""At this point, feel free to go back and modify your model architecture, dataset, and training process. At the end of the project, we will evaluate your network on a set of test data!"""

#COMPETITION TIME
# The staff has chosen a test set of images that you will evaluate your trained network on! Let's see how well you can do on our dataset! 
test_dir = 'drive/My Drive/val'
test_datagen = ImageDataGenerator(rescale=1./255)
test_batchsize = 10
 
# Data generator for test data
test_generator = test_datagen.flow_from_directory(
        test_dir,
        target_size=(224, 224),
        batch_size=test_batchsize,
        class_mode='categorical',
        shuffle=False)

# Evaluate the model
results = model.evaluate_generator(generator=test_generator, steps=test_generator.n // test_generator.batch_size)

print(results)